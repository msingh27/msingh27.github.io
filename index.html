
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
	<meta name=viewport content='width=800'>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
      /* Color scheme stolen from Sergey Karayev */
      a {
      color: #1772d0;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px;
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22 px;
      }
      papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
      }
      name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
      }
	.fade {
	   transition: opacity .2s ease-in-out;
	   -moz-transition: opacity .2s ease-in-out;
	   -webkit-transition: opacity .2s ease-in-out;
	   }
	  


	img {
	    display: inline;
	    margin: 0 auto;
	    width: 100%;
	}
   .image-cropper {
      width: 270px;
      height: 200px;
      position: relative;
      overflow: hidden;
      border-radius: 50%;
  }
    </style>
    <link rel="icon" type="image" href="img/logo.jpg">
    <title>Mayank Singh</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="67%" valign="middle">
                <p align="center">
                  <name>Mayank Singh</name>
                  </font>
                <p align>I am currently working in the Media and Data Science Research team at Adobe, Noida.
                  I am interested in the field of deep learning with a focus on adversarial machine learning, reinforcement learning and self-supervision. Prior to my work, I did my undergraduation from <a href="http://www.iitkgp.ac.in/">Indian Institute of Tenchnology Kharagpur</a> with a major in Mathematics and Computing.
                 
                <p align=center>
<a href="mailto:mayanksingh027@gmail.com">Email</a> &nbsp/&nbsp
<a href="https://www.linkedin.com/in/mayank-singh-3b031660/">LinkedIn</a> &nbsp/&nbsp
<a href="files/resume.pdf">Resume</a> &nbsp/&nbsp
<a href="https://scholar.google.com/citations?user=RgeKqSAAAAAJ&hl=en">Google Scholar</a>

                </p>
              </td>
              <td width="33%"><img class="image-cropper" src="img/photo.jpg"></td>
            </tr>
          </table>
            

           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <heading style="font-size:22px"> Publication</heading>
              </td>
            </tr>

            
              <td width="30%"><img id="img-opt" src="img/few_shot.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/pdf/1907.12087.pdf">
        <papertitle>Charting the Right Manifold: Manifold Mixup for Few-shot Learning</papertitle></a><br>
                        
                      <p>Used self-supervision techniques - rotation and exemplar, followed by manifold mixup for few-shot classification tasks.
                      <br><br>
                      The proposed approach beats the current state-of-the-art accuracy on mini-ImageNet, CUB and CIFAR-FS datasets by 3-8%.
                      <br><br>
                      Work accepted at WACV, 2020.       
                      </p>
                      </a> </p>
                    </td>
                  </tr>
            <tr >
              <td width="30%"><img id="img-opt" src="img/lat.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/pdf/1905.05186.pdf">
        <papertitle>Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models</papertitle></a><br>
                        
                      <p>Analyzed the adversarial trained models for vulnerability against adversarial perturbations at the latent layers.
                      <br><br>
                      The algorithm achieved the state-of-the art adversarial accuracy against strong adversarial attacks.      
                      <br><br>
                      Work accepted at IJCAI, 2019.
                      </p>
                       
                      </a> </p>
                    </td>
            </tr>    

		<tr >
              <td width="30%"><img id="img-opt" src="img/robust_attr.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/1911.13073">
        <papertitle>On the Benefits of Attributional Robustness</papertitle></a><br>
                        
                      <p>Proposed a robust attribution training methodology that maximizes the alignment between the input and its attribution map.
                      <br><br>
                      The proposed technique induces immunity to adversarial and common perturbations on standard visiondatasets. It achieves state-of-the-art accuracy in weakly supervised object localization on CUB dataset.    
                      <br><br>
                      Arxiv preprint.
                      </p>
                       
                      </a> </p>
                    </td>
            </tr>  

            <tr >
              <td width="30%"><img id="img-opt" src="img/condition.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="http://iwaise2018.it.nuigalway.ie/wp-content/uploads/2018/09/Neural-Networks-in-an-Adversarial-Setting-and.pdf">
        <papertitle>Neural Networks in Adversarial Setting and Ill-Conditioned Weight Space</papertitle></a><br>
                        
                      <p>Proposed  a  methodology  to  increase  the  robustness  of  neural  networks  against  adversarial  attacks  by promoting weights to be in well-conditioned space.
                      <br><br>
                      IWAISe : ECML workshop, 2018.
                      </p>
                       
                      </a> </p>
                    </td>
            </tr>  
            
		<tr >
              <td width="30%"><img id="img-opt" src="img/universal.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/1912.00466">
        <papertitle>A Method for Computing Class-wise Universal Adversarial Perturbations</papertitle></a><br>
                        
                      <p>Proposed a data-independent method for generating class-wise universal adversarial perturbations.
                      <br><br>
                      Arxiv preprint
                      </p>
                       
                      </a> </p>
                    </td>
            </tr>  
                    
		<tr >
              <td width="30%"><img id="img-opt" src="img/ecml_attr.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="http://www.research.ibm.com/labs/ireland/nemesis2018/pdf/paper4.pdf">
        <papertitle>Understanding Adversarial Space through the lens of Attribution</papertitle></a><br>
                        
                      <p>Used the attribution of images as an additional input to train a classifier that can detect adversarial examples.
                      <br><br>
      					Proposed a technique to obtain attribution maps using adversarial perturbations.
                      <br><br>
                      Nemesis : ECML workshop, 2018.
                      </p>
                       
                      </a> </p>
                    </td>
            </tr>  
                    


            <tr> 
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right"><font size="2">
                  <a href="http://www.cs.berkeley.edu/~barron/">inspired from this website</a>
                  </font>
                </p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
    </table>

<script type="text/javascript">
var sc_project=11673319; 
var sc_invisible=1; 
var sc_security="327094c7"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="http://statcounter.com/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11673319/0/327094c7/1/" alt="Web
Analytics Made Easy - StatCounter"></a></div></noscript>
<!-- End of Statcounter Code -->
  </body>
</html>
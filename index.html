
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
	<meta name=viewport content='width=800'>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
      /* Color scheme stolen from Sergey Karayev */
      a {
      color: #1772d0;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 24 px;
      }
      papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
      }
      name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 34px;
      }
	.fade {
	   transition: opacity .2s ease-in-out;
	   -moz-transition: opacity .2s ease-in-out;
	   -webkit-transition: opacity .2s ease-in-out;
	   }
	  


	img {
	    display: inline;
	    margin: 0 auto;
	    width: 100%;
	}
   .image-cropper {
      width: 270px;
      height: 200px;
      position: relative;
      overflow: hidden;
      border-radius: 50%;
  }
    </style>
    <link rel="icon" type="image" href="img/logo.jpg">
    <title>Mayank Singh</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="67%" valign="middle">
                <p align="center">
                  <name>Mayank Singh</name>
                  </font>
                <p align>I am a second year graduate student at The Robotics Institute (MSR), <a href="https://www.ri.cmu.edu/">Carnegie Mellon University</a>. I am advised by Prof. <a href="https://www.cs.cmu.edu/~katef/"> Katerina Fragkiadaki </a> and collaborate with Prof. <a href="https://shubhtuls.github.io/"> Shubham Tulsiani</a>. My research interests are 3D computer vision, adversarial machine learning, generative models and few-shot learning. 
                <p align>Before this, I was working at Media and Data Science Research Labs Adobe, India and had the opportunity to collaborate with Prof. <a href="https://people.iith.ac.in/vineethnb/"> Vineeth N Balasubramanian</a>. I graduated from <a href="http://www.iitkgp.ac.in/">Indian Institute of Technology Kharagpur</a> in Mathematics and Computing. </p>
                 
                <p align=center>
[<a href="mailto:mayanksingh027@gmail.com">Email</a>] &nbsp&nbsp
[<a href="https://www.linkedin.com/in/mayank-singh-3b031660/">LinkedIn</a>] &nbsp&nbsp
[<a href="files/resume_onepage.pdf">Resume</a>] &nbsp&nbsp
[<a href="https://scholar.google.com/citations?user=RgeKqSAAAAAJ&hl=en">Google Scholar</a>]

                </p>
              </td>
              <!-- <td width="33%"><img class="image-cropper" src="img/photo.jpg"></td> -->
              <td width="33%"><img src="img/photo.jpg"></td>

            </tr>
          </table>
            

           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <br>
                <heading style="font-size:22px"> Selected Publications </heading>
              <br>
            </tr>
            
            <tr >
              <td width="30%"><img id="img-opt" src="img/parts_arch.jpg" alt="project_img" width="160" style="border-style: none">
                  </td>
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/2304.14382">
        <papertitle>Analogy-Forming Transformers for Few-Shot 3D Parsing</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          <a href="https://nickgkan.github.io/">Nikolaos Gkanatsios</a><sup>&#42;</sup> Mayank Singh<sup>&#42;</sup>, <a href="https://zfang399.github.io/">Zhaoyuan Fang</a>, <a href="https://shubhtuls.github.io/">Shubham Tulsiani</a>, <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadak</a></i><br>
                        
                      <p>We present <i>Analogical Networks</i>, a model that casts fine-grained 3D visual parsing as analogy-forming inference: instead of mapping input scenes to part labels, which is hard to adapt in a few-shot manner to novel inputs, our model retrieves related scenes from memory and their corresponding part structures, and predicts analogous part structures in the input object 3D point cloud, via an end-to-end learnable modulation mechanism. 
                      <br><br>
                      Work acccepted at ICLR 2023.
                      <!-- </p> -->
                      [<a href="https://openreview.net/pdf?id=SRIQZTh0IK">Paper</a>]
                      [<a href="https://analogicalnets.github.io/">Webpage</a>]
                      [<a href="https://github.com/nickgkan/analogicalnets">Code</a>]

                      </a> </p>
                    </td>
            </tr> 
            <tr >

            <tr >
              <td width="30%"><img id="img-opt" src="img/robust_attr.png" alt="project_img" width="160" style="border-style: none">
                  </td>
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/1911.13073">
        <papertitle>Attributional Robustness Training using Input-Gradient Spatial Alignment</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Mayank Singh<sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Puneet Mangla, <a href="https://a7b23.github.io/">Abhishek Sinha</a>, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a>, Balaji Krishnamurthy</i><br>
                        
                      <p>We propose a robust attribution training methodology <i>ART</i> that maximizes the alignment between the input and its attribution map. <i>ART</i> induces immunity to adversarial and common perturbations on standard vision datasets. It achieves state-of-the-art performance in weakly supervised object localization on CUB dataset.    
                      <br><br>
                      Work acccepted at ECCV 2020.
                      <!-- </p> -->
                      [<a href="https://arxiv.org/abs/1911.13073">Paper</a>]
                      [<a href="https://nupurkmr9.github.io/Attributional-Robustness/">Webpage</a>]
                      [<a href="https://github.com/nupurkmr9/Attributional-Robustness">Code</a>]

                      </a> </p>
                    </td>
            </tr> 

            <tr >
            <tr >
              <td width="30%"><img id="img-opt" src="img/lat.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/pdf/1905.05186.pdf">
        <papertitle>Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, Harshitha Machiraju, Balaji Krishnamurthy, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a></i><br>
                        
                      <p>We Analyze the adversarial trained models for vulnerability against adversarial perturbations in the latent layers. The algorithm achieved the state-of-the art adversarial accuracy against strong adversarial attacks.      
                      <br><br>
                      Work accepted at IJCAI, 2019.
                      <!-- </p>
                       
                      </a> </p> -->
                      [<a href="https://www.ijcai.org/Proceedings/2019/0385.pdf">Paper</a>]
                      [<a href="https://github.com/msingh27/LAT_adversarial_robustness">Code</a>]
                    </td>
            </tr>
            
            <tr >
              <td width="30%"><img id="img-opt" src="img/block_dip.png" alt="project_img" width="160" style="border-style: none">
                  </td>

                    <td valign="top" width="70%">
                      <p>
        <papertitle>Data InStance Prior (DISP) in Generative Adversarial Networks</papertitle><br>
        <i><span style="font-size: 10pt;">
          Puneet Mangla<sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a>, Balaji Krishnamurthy,</i><br>
        
                      <p>We propose a novel transfer learning technique for GANs in the limited data domain by leveraging informative data prior derived from self-supervised/supervised pretrained networks trained on a diverse source domain.
                      <br><br>
                      Work accepted at WACV, 2022.
                      <!-- </p> -->
                      <!-- </a> </p> -->
                      [<a href="https://arxiv.org/abs/2012.04256">Paper</a>]
                    </td>
            </tr>  

            <tr >
              <td width="30%"><img id="img-opt" src="img/ltgan.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p>
        <papertitle>LT-GAN: Self-Supervised GAN with Latent Transformation Detection</papertitle><br>
        <i><span style="font-size: 10pt;">
          Parth Patel<sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, Balaji Krishnamurthy,</i><br>
        
                      <p>We propose a self-supervised approach (LT-GAN) to improve the generation quality and diversity of images by estimating the GAN-induced transformation (i.e. transformation induced in the generated images by perturbing the latent space of generator).
                      <br><br>
                      Work accepted at WACV, 2021.
                      <!-- </p>
                      </a> </p>      -->              
                      [<a href="https://arxiv.org/abs/2010.09893">Paper</a>]
                    </td>
            </tr>

              
            
              <td width="30%"><img id="img-opt" src="img/few_shot.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/pdf/1907.12087.pdf">
        <papertitle>Charting the Right Manifold: Manifold Mixup for Few-shot Learning</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Puneet Mangla<sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a>, Balaji Krishnamurthy</i><br>               
                      <p>We Use self-supervision techniques like rotation prediction and exemplar, followed by manifold mixup for the few-shot classification tasks. The proposed approach beats the current state-of-the-art accuracy on mini-ImageNet, CUB and CIFAR-FS datasets by 3-8%.
                      <br><br>
                      Work accepted at WACV, 2020.       
                      <!-- </p>
                      </a> </p> -->
                      [<a href="https://openaccess.thecvf.com/content_WACV_2020/papers/Mangla_Charting_the_Right_Manifold_Manifold_Mixup_for_Few-shot_Learning_WACV_2020_paper.pdf">Paper</a>]
                      [<a href="https://github.com/nupurkmr9/S2M2_fewshot">Code</a>]
                    </td>
                  </tr>
          <tr >
              <td width="30%"><img id="img-opt" src="img/iclr_trust.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/2005.01499">
        <papertitle>On the Benefits of Models with Perceptually-Aligned Gradients</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Gunjan Aggarwal<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup></i><br>
        
                      <p>In this paper, we leverage models with interpretable perceptually-aligned features and show that adversarial training with low max-perturbation bound can improve the performance of models for zero-shot and weakly supervised localization tasks.
                      <br><br>
                      Work accepted at ICLR workshop Towards Trustworthy ML, 2020.
                      <!-- </p>
                       
                      </a> </p> -->
                      [<a href="https://arxiv.org/abs/2005.01499">Paper</a>]
                    </td>
            </tr>    

            

		
             <!--
            <tr >
              <td width="30%"><img id="img-opt" src="img/condition.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="http://iwaise2018.it.nuigalway.ie/wp-content/uploads/2018/09/Neural-Networks-in-an-Adversarial-Setting-and.pdf">
        <papertitle>Neural Networks in Adversarial Setting and Ill-Conditioned Weight Space</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, Balaji Krishnamurthy</i><br>
                        
                      <p>We propose a methodology to increase the robustness of neural networks against adversarial attacks by promoting weights to be in well-conditioned space.
                      <br><br>
                      IWAISe : ECML workshop, 2018.

                      [<a href="http://iwaise2018.it.nuigalway.ie/wp-content/uploads/2018/09/Neural-Networks-in-an-Adversarial-Setting-and.pdf">Paper</a>]
                    </td>
            </tr>  
            
		<tr >
              <td width="30%"><img id="img-opt" src="img/universal.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/1912.00466">
        <papertitle>A Method for Computing Class-wise Universal Adversarial Perturbations</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Tejus Gupta<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, Balaji Krishnamurthy</i><br>
                        
                      <p>We propose a data-independent method for generating class-wise universal adversarial perturbations.
                      <br><br>
                      Arxiv preprint

                      [<a href="https://arxiv.org/abs/1912.00466">Paper</a>]
                    </td>
            </tr>  
                    
		<tr >
              <td width="30%"><img id="img-opt" src="img/ecml_attr.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="http://www.research.ibm.com/labs/ireland/nemesis2018/pdf/paper4.pdf">
        <papertitle>Understanding Adversarial Space through the lens of Attribution</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Mayank Singh<sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>,  Balaji Krishnamurthy</i><br>
                        
                      <p>We use the attribution of images as an additional input to train a classifier that can detect adversarial examples. Also, we propose a technique to obtain attribution maps using adversarial perturbations.
                      <br><br>
                      Nemesis : ECML workshop, 2018.

                      [<a href="http://www.research.ibm.com/labs/ireland/nemesis2018/pdf/paper4.pdf">Paper</a>]
                      <br> <sup>&#42;</sup> denotes equal contribution
                    </td>
            </tr>  
             -->         


            <tr> 
          <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
              <p align="left"><font size="2">
                <sup>&#42;</sup> denotes equal contribution
                </font>
          
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right"><font size="2">
                  <a href="http://www.cs.berkeley.edu/~barron/">inspired from this website</a>
                  </font>
                </p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
    </table>

<script type="text/javascript">
var sc_project=11673319; 
var sc_invisible=1; 
var sc_security="327094c7"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="http://statcounter.com/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11673319/0/327094c7/1/" alt="Web
Analytics Made Easy - StatCounter"></a></div></noscript>
<!-- End of Statcounter Code -->
  </body>
</html>

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
	<meta name=viewport content='width=800'>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
      /* Color scheme stolen from Sergey Karayev */
      a {
      color: #1772d0;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px;
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22 px;
      }
      papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
      }
      name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
      }
	.fade {
	   transition: opacity .2s ease-in-out;
	   -moz-transition: opacity .2s ease-in-out;
	   -webkit-transition: opacity .2s ease-in-out;
	   }
	  


	img {
	    display: inline;
	    margin: 0 auto;
	    width: 100%;
	}
   .image-cropper {
      width: 270px;
      height: 200px;
      position: relative;
      overflow: hidden;
      border-radius: 50%;
  }
    </style>
    <link rel="icon" type="image" href="img/logo.jpg">
    <title>Mayank Singh</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="67%" valign="middle">
                <p align="center">
                  <name>Mayank Singh</name>
                  </font>
                <p align>I am currently working in the Media and Data Science Research team at Adobe, Noida.
                  I am interested in the field of deep learning with a focus on adversarial machine learning, reinforcement learning and self-supervision. Prior to my work, I did my undergraduation from <a href="http://www.iitkgp.ac.in/">Indian Institute of Technology Kharagpur</a> with a major in Mathematics and Computing.
                 
                <p align=center>
<a href="mailto:mayanksingh027@gmail.com">Email</a> &nbsp/&nbsp
<a href="https://www.linkedin.com/in/mayank-singh-3b031660/">LinkedIn</a> &nbsp/&nbsp
<a href="files/resume.pdf">Resume</a> &nbsp/&nbsp
<a href="https://scholar.google.com/citations?user=RgeKqSAAAAAJ&hl=en">Google Scholar</a>

                </p>
              </td>
              <td width="33%"><img class="image-cropper" src="img/photo.jpg"></td>
            </tr>
          </table>
            

           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <heading style="font-size:22px"> Publication</heading>
              </td>
            </tr>
            
            <tr >
              <td width="30%"><img id="img-opt" src="img/ltgan.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p>
        <papertitle>LT-GAN: Self-Supervised GAN with Latent Transformation Detection</papertitle><br>
        <i><span style="font-size: 10pt;">
          Parth Patel<sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Balaji Krishnamurthy,</i><br>
        
                      <p>We propose a self-supervised approach (LT-GAN) to improve the generation quality and diversity of images by estimating the GAN-induced transformation (i.e. transformation induced in the generated images by perturbing the latent space of generator).
                      <br><br>
                      Work accepted at WACV, 2021.
                      </p>
                    </td>
            </tr> 

            <tr >
              <td width="30%"><img id="img-opt" src="img/robust_attr.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/1911.13073">
        <papertitle>Attributional Robustness Training using Input-Gradient Spatial Alignment</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Mayank Singh<sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Puneet Mangla, <a href="https://a7b23.github.io/">Abhishek Sinha</a>, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a>, Balaji Krishnamurthy</i><br>
                        
                      <p>We propose a robust attribution training methodology <i>ART</i> that maximizes the alignment between the input and its attribution map. <i>ART</i> induces immunity to adversarial and common perturbations on standard vision datasets. It achieves state-of-the-art performance in weakly supervised object localization on CUB dataset.    
                      <br><br>
                      Work acccepted at ECCV 2020.
                      </p>
                      [<a href="https://arxiv.org/abs/1911.13073">Paper</a>]
                      [<a href="https://nupurkmr9.github.io/Attributional-Robustness/">Webpage</a>]
                      [<a href="https://github.com/nupurkmr9/Attributional-Robustness">Code</a>]

                      </a> </p>
                    </td>
            </tr>  
            
              <td width="30%"><img id="img-opt" src="img/few_shot.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/pdf/1907.12087.pdf">
        <papertitle>Charting the Right Manifold: Manifold Mixup for Few-shot Learning</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Puneet Mangla<sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a>, Balaji Krishnamurthy</i><br>               
                      <p>We Use self-supervision techniques like rotation prediction and exemplar, followed by manifold mixup for the few-shot classification tasks. The proposed approach beats the current state-of-the-art accuracy on mini-ImageNet, CUB and CIFAR-FS datasets by 3-8%.
                      <br><br>
                      Work accepted at WACV, 2020.       
                      </p>
                      </a> </p>
                      [<a href="https://openaccess.thecvf.com/content_WACV_2020/papers/Mangla_Charting_the_Right_Manifold_Manifold_Mixup_for_Few-shot_Learning_WACV_2020_paper.pdf">Paper</a>]
                      [<a href="https://github.com/nupurkmr9/S2M2_fewshot">Code</a>]
                    </td>
                  </tr>
          <tr >
              <td width="30%"><img id="img-opt" src="img/iclr_trust.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/2005.01499">
        <papertitle>On the Benefits of Models with Perceptually-Aligned Gradients</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Gunjan Aggarwal<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup></i><br>
        
                      <p>In this paper, we leverage models with interpretable perceptually-aligned features and show that adversarial training with low max-perturbation bound can improve the performance of models for zero-shot and weakly supervised localization tasks.
                      <br><br>
                      Work accepted at ICLR workshop Towards Trustworthy ML, 2020.
                      </p>
                       
                      </a> </p>
                      [<a href="https://arxiv.org/abs/2005.01499">Paper</a>]
                    </td>
            </tr>    

        <tr >
            <tr >
              <td width="30%"><img id="img-opt" src="img/lat.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/pdf/1905.05186.pdf">
        <papertitle>Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, Harshitha Machiraju, Balaji Krishnamurthy, <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N Balasubramanian</a></i><br>
                        
                      <p>We Analyze the adversarial trained models for vulnerability against adversarial perturbations in the latent layers. The algorithm achieved the state-of-the art adversarial accuracy against strong adversarial attacks.      
                      <br><br>
                      Work accepted at IJCAI, 2019.
                      </p>
                       
                      </a> </p>
                      [<a href="https://www.ijcai.org/Proceedings/2019/0385.pdf">Paper</a>]
                      [<a href="https://github.com/msingh27/LAT_adversarial_robustness">Code</a>]
                    </td>
            </tr>    

		

            <tr >
              <td width="30%"><img id="img-opt" src="img/condition.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="http://iwaise2018.it.nuigalway.ie/wp-content/uploads/2018/09/Neural-Networks-in-an-Adversarial-Setting-and.pdf">
        <papertitle>Neural Networks in Adversarial Setting and Ill-Conditioned Weight Space</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, Balaji Krishnamurthy</i><br>
                        
                      <p>We propose a methodology to increase the robustness of neural networks against adversarial attacks by promoting weights to be in well-conditioned space.
                      <br><br>
                      IWAISe : ECML workshop, 2018.
                      </p>
                       
                      </a> </p>
                      [<a href="http://iwaise2018.it.nuigalway.ie/wp-content/uploads/2018/09/Neural-Networks-in-an-Adversarial-Setting-and.pdf">Paper</a>]
                    </td>
            </tr>  
            
		<tr >
              <td width="30%"><img id="img-opt" src="img/universal.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="https://arxiv.org/abs/1912.00466">
        <papertitle>A Method for Computing Class-wise Universal Adversarial Perturbations</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Tejus Gupta<sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, Mayank Singh<sup>&#42;</sup>, Balaji Krishnamurthy</i><br>
                        
                      <p>We propose a data-independent method for generating class-wise universal adversarial perturbations.
                      <br><br>
                      Arxiv preprint
                      </p>
                       
                      </a> </p>
                      [<a href="https://arxiv.org/abs/1912.00466">Paper</a>]
                    </td>
            </tr>  
                    
		<tr >
              <td width="30%"><img id="img-opt" src="img/ecml_attr.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a href="http://www.research.ibm.com/labs/ireland/nemesis2018/pdf/paper4.pdf">
        <papertitle>Understanding Adversarial Space through the lens of Attribution</papertitle></a><br>
        <i><span style="font-size: 10pt;">
          Mayank Singh<sup>&#42;</sup>, <a href="https://nupurkmr9.github.io/">Nupur Kumari</a><sup>&#42;</sup>, <a href="https://a7b23.github.io/">Abhishek Sinha</a><sup>&#42;</sup>,  Balaji Krishnamurthy</i><br>
                        
                      <p>We use the attribution of images as an additional input to train a classifier that can detect adversarial examples. Also, we propose a technique to obtain attribution maps using adversarial perturbations.
                      <br><br>
                      Nemesis : ECML workshop, 2018.
                      </p>
                       
                      </a> </p>
                      [<a href="http://www.research.ibm.com/labs/ireland/nemesis2018/pdf/paper4.pdf">Paper</a>]
                      <br> <sup>&#42;</sup> denotes equal contribution
                    </td>
            </tr>  
                    


            <tr> 
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right"><font size="2">
                  <a href="http://www.cs.berkeley.edu/~barron/">inspired from this website</a>
                  </font>
                </p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
    </table>

<script type="text/javascript">
var sc_project=11673319; 
var sc_invisible=1; 
var sc_security="327094c7"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="http://statcounter.com/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11673319/0/327094c7/1/" alt="Web
Analytics Made Easy - StatCounter"></a></div></noscript>
<!-- End of Statcounter Code -->
  </body>
</html>